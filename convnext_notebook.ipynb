{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CIFAR-10 Image Classification with ConvNeXt and Optuna\n",
        "\n",
        "This notebook demonstrates training a ConvNeXt classifier on the CIFAR-10 dataset using Optuna for hyperparameter tuning.  The dataset is exported from the original CIFAR-10 binary batches into a folder structure with separate `train`, `val`, and `test` splits.  Throughout the tuning and final training runs, detailed metrics (loss, accuracy, precision, recall, F1, and specificity) are logged for each epoch.  Curves and confusion matrices are automatically generated and stored in the `./artifacts` directory.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install Dependencies ([modal.com](https://modal.com))\n",
        "\n",
        "Install necessary Python packages.  This cell uses `pip` via the `%uv` magic to ensure dependencies are available for the rest of the notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2mUsing Python 3.12.6 environment at: /usr/local\u001b[0m\r\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠋\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mtimm==1.0.21                                                                  \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2moptuna==4.5.0                                                                 \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mscikit-learn==1.7.1                                                           \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mtorchmetrics==1.8.2                                                           \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mjiwer==4.0.0                                                                  \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mopencv-python==4.12.0.88                                                      \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mtqdm==4.67.1                                                                  \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mmatplotlib==3.10.6                                                            \u001b[0m\r\u001b[2K\u001b[37m⠹\u001b[0m \u001b[2mmatplotlib==3.10.6                                                            \u001b[0m\r\u001b[2K\u001b[37m⠹\u001b[0m \u001b[2mtorch==2.8.0+cu129                                                            \u001b[0m\r\u001b[2K\u001b[37m⠹\u001b[0m \u001b[2mtorchvision==0.23.0+cu129                                                     \u001b[0m\r\u001b[2K\u001b[37m⠹\u001b[0m \u001b[2mpyyaml==6.0.2                                                                 \u001b[0m\r\u001b[2K\u001b[37m⠹\u001b[0m \u001b[2mhuggingface-hub==0.34.4                                                       \u001b[0m\r\u001b[2K\u001b[37m⠹\u001b[0m \u001b[2msafetensors==0.6.2                                                            \u001b[0m\r\u001b[2K\u001b[37m⠹\u001b[0m \u001b[2malembic==1.17.0                                                               \u001b[0m\r\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2malembic==1.17.0                                                               \u001b[0m\r\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2mcolorlog==6.10.1                                                              \u001b[0m\r\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2mnumpy==2.1.2                                                                  \u001b[0m\r\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2mnumpy==2.1.2                                                                  \u001b[0m\r\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2mpackaging==25.0                                                               \u001b[0m\r\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2msqlalchemy==2.0.43                                                            \u001b[0m\r\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2mscipy==1.16.1                                                                 \u001b[0m\r\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2mjoblib==1.5.2                                                                 \u001b[0m\r\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2mthreadpoolctl==3.6.0                                                          \u001b[0m\r\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2mlightning-utilities==0.15.2                                                   \u001b[0m\r\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2mclick==8.2.1                                                                  \u001b[0m\r\u001b[2K\u001b[37m⠸\u001b[0m \u001b[2mnvidia-cublas-cu12==12.9.1.4                                                  \u001b[0m\r\u001b[2K\u001b[2mResolved \u001b[1m64 packages\u001b[0m \u001b[2min 482ms\u001b[0m\u001b[0m\r\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/0)                                                   \r\u001b[2K\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)                                                  \r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)                                                  \r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/28.74 KiB            \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB          \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/76.67 KiB                     \u001b[2A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 14.89 KiB/76.67 KiB                   \u001b[2A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 14.89 KiB/76.67 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/2.41 MiB                      \u001b[3A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 14.89 KiB/76.67 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/391.48 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/2.41 MiB                      \u001b[4A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 14.89 KiB/76.67 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/2.41 MiB                      \u001b[4A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 14.89 KiB/76.67 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/3.01 MiB                      \u001b[5A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[5A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 14.89 KiB/76.67 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/3.01 MiB                    \u001b[5A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[5A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 14.89 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/3.01 MiB                    \u001b[6A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[6A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 14.89 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 14.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/3.01 MiB                    \u001b[6A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[6A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 14.89 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 14.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/3.01 MiB                    \u001b[7A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[7A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 14.89 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 14.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/3.01 MiB                    \u001b[7A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[7A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mjiwer     \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/22.49 KiB\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 14.89 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 14.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/3.01 MiB                    \u001b[8A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[8A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mjiwer     \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 14.92 KiB/22.49 KiB\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 14.89 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 14.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/3.01 MiB                    \u001b[8A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[8A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mjiwer     \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 14.92 KiB/22.49 KiB\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 14.89 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 14.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/3.01 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/63.94 MiB                  \u001b[9A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[9A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mjiwer     \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 14.92 KiB/22.49 KiB\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 14.89 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 14.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/3.01 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.90 KiB/63.94 MiB                \u001b[9A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[9A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mcolorlog  \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 11.47 KiB/11.47 KiB\r\n",
            "\u001b[2mjiwer     \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 14.92 KiB/22.49 KiB\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 14.89 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 14.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 31.89 KiB/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/3.01 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 56.13 KiB/63.94 MiB                \u001b[10A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[10A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mcolorlog  \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 11.47 KiB/11.47 KiB\r\n",
            "\u001b[2mjiwer     \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 22.49 KiB/22.49 KiB\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 30.89 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 30.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 32.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 32.00 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 72.74 KiB/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 502.21 KiB/3.01 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.70 MiB/63.94 MiB                 \u001b[10A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[10A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mjiwer     \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 22.49 KiB/22.49 KiB\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 46.89 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 46.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 32.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 48.00 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 168.74 KiB/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 1.02 MiB/3.01 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.25 MiB/63.94 MiB                 \u001b[9A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[9A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 16.00 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 62.89 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 62.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 32.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 48.00 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 296.74 KiB/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 1.02 MiB/3.01 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.47 MiB/63.94 MiB                 \u001b[8A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[8A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 28.74 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 62.89 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 62.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 32.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 63.66 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 376.74 KiB/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 1.24 MiB/3.01 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.47 MiB/63.94 MiB                 \u001b[8A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[8A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/10)\r\n",
            "\u001b[2mlightning-utilities\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 28.74 KiB/28.74 KiB\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 76.67 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 94.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 48.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 88.40 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 1.12 MiB/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 1.35 MiB/3.01 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 3.14 MiB/63.94 MiB                 \u001b[8A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[8A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (2/10)\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 76.67 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 94.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 64.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 88.40 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 1.41 MiB/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 1.35 MiB/3.01 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 3.94 MiB/63.94 MiB                 \u001b[7A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[7A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (2/10)\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 76.67 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 126.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 64.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 104.40 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 1.49 MiB/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 1.35 MiB/3.01 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 5.06 MiB/63.94 MiB                 \u001b[7A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[7A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (2/10)\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 76.67 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 142.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 64.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 120.40 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 1.49 MiB/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 1.35 MiB/3.01 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 7.18 MiB/63.94 MiB                 \u001b[7A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[7A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (2/10)\r\n",
            "\u001b[2mmako      \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 76.67 KiB/76.67 KiB\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 158.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 64.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 124.36 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 1.51 MiB/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 1.35 MiB/3.01 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 9.94 MiB/63.94 MiB                 \u001b[7A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[7A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (2/10)\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 174.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 64.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 136.40 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 1.51 MiB/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 1.37 MiB/3.01 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 11.30 MiB/63.94 MiB                \u001b[6A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[6A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (2/10)\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 174.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 64.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 152.40 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 1.52 MiB/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 1.37 MiB/3.01 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 12.16 MiB/63.94 MiB                \u001b[6A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[6A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/10)\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 190.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 80.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 200.40 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 1.56 MiB/2.41 MiB\r\n",
            "\u001b[2mrapidfuzz \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 1.51 MiB/3.01 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 13.82 MiB/63.94 MiB                \u001b[6A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[6A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/10)\r\n",
            "\u001b[2malembic   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 206.88 KiB/241.65 KiB\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 96.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 248.40 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 1.60 MiB/2.41 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 13.82 MiB/63.94 MiB                \u001b[5A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[5A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/10)\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 144.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 328.40 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 1.63 MiB/2.41 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 13.86 MiB/63.94 MiB                \u001b[4A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[4A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/10)\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 160.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 344.40 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 1.63 MiB/2.41 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 13.86 MiB/63.94 MiB                \u001b[4A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[4A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/10)\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 224.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 424.40 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 1.71 MiB/2.41 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 15.40 MiB/63.94 MiB                \u001b[4A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[4A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (4/10)\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 240.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 440.40 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 1.74 MiB/2.41 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 17.11 MiB/63.94 MiB                \u001b[4A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[4A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (6/10)\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 240.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 456.40 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 1.76 MiB/2.41 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 20.35 MiB/63.94 MiB                \u001b[4A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[4A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (6/10)\r\n",
            "\u001b[2moptuna    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 352.00 KiB/391.48 KiB\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 584.40 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 2.15 MiB/2.41 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 21.35 MiB/63.94 MiB                \u001b[4A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[4A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (6/10)\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 616.40 KiB/960.12 KiB\r\n",
            "\u001b[2mtimm      \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 2.21 MiB/2.41 MiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 21.35 MiB/63.94 MiB                \u001b[3A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[3A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (6/10)\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 776.40 KiB/960.12 KiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 21.82 MiB/63.94 MiB                \u001b[2A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (6/10)\r\n",
            "\u001b[2mtorchmetrics\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 808.40 KiB/960.12 KiB\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 22.00 MiB/63.94 MiB                \u001b[2A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (6/10)\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 22.00 MiB/63.94 MiB                \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (6/10)\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 23.58 MiB/63.94 MiB                \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/10)\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 26.01 MiB/63.94 MiB                \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/10)\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 27.75 MiB/63.94 MiB                \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/10)\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 30.06 MiB/63.94 MiB                \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/10)\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 32.92 MiB/63.94 MiB                \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/10)\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 36.02 MiB/63.94 MiB                \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/10)\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 39.02 MiB/63.94 MiB                \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/10)\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 41.22 MiB/63.94 MiB                \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/10)\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 44.27 MiB/63.94 MiB                \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/10)\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 46.93 MiB/63.94 MiB                \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/10)\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 49.74 MiB/63.94 MiB                \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/10)\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 52.25 MiB/63.94 MiB                \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/10)\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 54.72 MiB/63.94 MiB                \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/10)\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 57.87 MiB/63.94 MiB                \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/10)\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 59.11 MiB/63.94 MiB                \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/10)\r\n",
            "\u001b[2mopencv-python\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 61.94 MiB/63.94 MiB                \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (9/10)                                                  \r\u001b[2K\u001b[2mPrepared \u001b[1m10 packages\u001b[0m \u001b[2min 1.58s\u001b[0m\u001b[0m\r\n",
            "░░░░░░░░░░░░░░░░░░░░ [0/0] \u001b[2mInstalling wheels...                                 \u001b[0m\r\u001b[2K░░░░░░░░░░░░░░░░░░░░ [0/10] \u001b[2mInstalling wheels...                                \u001b[0m\r\u001b[2K░░░░░░░░░░░░░░░░░░░░ [0/10] \u001b[2mcolorlog==6.10.1                                    \u001b[0m\r\u001b[2K██░░░░░░░░░░░░░░░░░░ [1/10] \u001b[2mcolorlog==6.10.1                                    \u001b[0m\r\u001b[2K██░░░░░░░░░░░░░░░░░░ [1/10] \u001b[2mjiwer==4.0.0                                        \u001b[0m\r\u001b[2K████░░░░░░░░░░░░░░░░ [2/10] \u001b[2mjiwer==4.0.0                                        \u001b[0m\r\u001b[2K████░░░░░░░░░░░░░░░░ [2/10] \u001b[2mlightning-utilities==0.15.2                         \u001b[0m\r\u001b[2K██████░░░░░░░░░░░░░░ [3/10] \u001b[2mlightning-utilities==0.15.2                         \u001b[0m\r\u001b[2K██████░░░░░░░░░░░░░░ [3/10] \u001b[2mmako==1.3.10                                        \u001b[0m\r\u001b[2K████████░░░░░░░░░░░░ [4/10] \u001b[2mmako==1.3.10                                        \u001b[0m\r\u001b[2K████████░░░░░░░░░░░░ [4/10] \u001b[2mrapidfuzz==3.14.1                                   \u001b[0m\r\u001b[2K██████████░░░░░░░░░░ [5/10] \u001b[2mrapidfuzz==3.14.1                                   \u001b[0m\r\u001b[2K██████████░░░░░░░░░░ [5/10] \u001b[2malembic==1.17.0                                     \u001b[0m\r\u001b[2K████████████░░░░░░░░ [6/10] \u001b[2malembic==1.17.0                                     \u001b[0m\r\u001b[2K████████████░░░░░░░░ [6/10] \u001b[2mopencv-python==4.12.0.88                            \u001b[0m\r\u001b[2K██████████████░░░░░░ [7/10] \u001b[2mopencv-python==4.12.0.88                            \u001b[0m\r\u001b[2K██████████████░░░░░░ [7/10] \u001b[2moptuna==4.5.0                                       \u001b[0m\r\u001b[2K████████████████░░░░ [8/10] \u001b[2moptuna==4.5.0                                       \u001b[0m\r\u001b[2K████████████████░░░░ [8/10] \u001b[2mtimm==1.0.21                                        \u001b[0m\r\u001b[2K██████████████████░░ [9/10] \u001b[2mtimm==1.0.21                                        \u001b[0m\r\u001b[2K██████████████████░░ [9/10] \u001b[2mtorchmetrics==1.8.2                                 \u001b[0m\r\u001b[2K████████████████████ [10/10] \u001b[2mtorchmetrics==1.8.2                                \u001b[0m\r\u001b[2K\u001b[2mInstalled \u001b[1m10 packages\u001b[0m \u001b[2min 184ms\u001b[0m\u001b[0m\r\n",
            " \u001b[32m+\u001b[39m \u001b[1malembic\u001b[0m\u001b[2m==1.17.0\u001b[0m\r\n",
            " \u001b[32m+\u001b[39m \u001b[1mcolorlog\u001b[0m\u001b[2m==6.10.1\u001b[0m\r\n",
            " \u001b[32m+\u001b[39m \u001b[1mjiwer\u001b[0m\u001b[2m==4.0.0\u001b[0m\r\n",
            " \u001b[32m+\u001b[39m \u001b[1mlightning-utilities\u001b[0m\u001b[2m==0.15.2\u001b[0m\r\n",
            " \u001b[32m+\u001b[39m \u001b[1mmako\u001b[0m\u001b[2m==1.3.10\u001b[0m\r\n",
            " \u001b[32m+\u001b[39m \u001b[1mopencv-python\u001b[0m\u001b[2m==4.12.0.88\u001b[0m\r\n",
            " \u001b[32m+\u001b[39m \u001b[1moptuna\u001b[0m\u001b[2m==4.5.0\u001b[0m\r\n",
            " \u001b[32m+\u001b[39m \u001b[1mrapidfuzz\u001b[0m\u001b[2m==3.14.1\u001b[0m\r\n",
            " \u001b[32m+\u001b[39m \u001b[1mtimm\u001b[0m\u001b[2m==1.0.21\u001b[0m\r\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorchmetrics\u001b[0m\u001b[2m==1.8.2\u001b[0m\r\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%uv pip install timm optuna scikit-learn torchmetrics jiwer opencv-python tqdm matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports and Basic Utilities\n",
        "\n",
        "Import required libraries and define helper functions for seeding and device selection.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import json\n",
        "import csv\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import optuna\n",
        "import timm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Mixed precision scaler (PyTorch 2.5+)\n",
        "from torch import amp\n",
        "SCALER = amp.GradScaler('cuda', enabled=True)\n",
        "\n",
        "def seed_everything(seed: int = 42) -> None:\n",
        "    \"\"\"Seed all random number generators for reproducibility.\"\"\"\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "def device_auto() -> torch.device:\n",
        "    \"\"\"Return the available device: CUDA if present, else CPU.\"\"\"\n",
        "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset and Transform Classes\n",
        "\n",
        "Define a simple classification transform and a dataset class that reads from a folder structure organized as `<root>/<split>/<class>/<images>`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "class ClassificationTransform:\n",
        "    \"\"\"Apply random augmentation and normalisation for classification.\"\"\"\n",
        "    def __init__(self, size: int = 224, train: bool = True) -> None:\n",
        "        self.size = size\n",
        "        self.train = train\n",
        "\n",
        "    def __call__(self, img_bgr: np.ndarray) -> torch.Tensor:\n",
        "        # Convert BGR (OpenCV) to RGB (PIL)\n",
        "        img = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "        if self.train:\n",
        "            h, w = img.shape[:2]\n",
        "            # Random scale crop\n",
        "            scale = np.random.uniform(0.7, 1.0)\n",
        "            nh, nw = int(h * scale), int(w * scale)\n",
        "            y0 = np.random.randint(0, max(1, h - nh + 1))\n",
        "            x0 = np.random.randint(0, max(1, w - nw + 1))\n",
        "            img = img[y0:y0 + nh, x0:x0 + nw]\n",
        "            # Random brightness/contrast\n",
        "            if np.random.rand() < 0.5:\n",
        "                alpha = np.random.uniform(0.8, 1.2)  # contrast\n",
        "                beta = np.random.randint(-20, 20)    # brightness\n",
        "                img = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
        "            # Random horizontal flip\n",
        "            if np.random.rand() < 0.5:\n",
        "                img = img[:, ::-1, :]\n",
        "        # Resize to target size\n",
        "        img = cv2.resize(img, (self.size, self.size), interpolation=cv2.INTER_LINEAR)\n",
        "        # Convert to tensor and normalise\n",
        "        t = torch.tensor(img.transpose(2, 0, 1), dtype=torch.float32) / 255.0\n",
        "        # Normalise using ImageNet mean and std\n",
        "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
        "        std  = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
        "        t = (t - mean) / std\n",
        "        return t\n",
        "\n",
        "class ClassificationDataset(Dataset):\n",
        "    \"\"\"A dataset for image classification organised as <root>/<split>/<class>/<images>.\"\"\"\n",
        "    def __init__(self, root: str, split: str, transform: ClassificationTransform, class_to_idx: Dict[str, int] = None) -> None:\n",
        "        self.root = Path(root)\n",
        "        self.split = split\n",
        "        self.transform = transform\n",
        "        self.samples: List[Tuple[str, int]] = []\n",
        "        # Build class mapping\n",
        "        if class_to_idx is None:\n",
        "            classes = sorted([p.name for p in (self.root / split).iterdir() if p.is_dir()])\n",
        "            self.class_to_idx = {c: i for i, c in enumerate(classes)}\n",
        "        else:\n",
        "            self.class_to_idx = dict(class_to_idx)\n",
        "            # Ensure directory exists for every class\n",
        "            for c in self.class_to_idx.keys():\n",
        "                (self.root / split / c).mkdir(parents=True, exist_ok=True)\n",
        "        # Collect samples (image path, label)\n",
        "        for cls, idx in self.class_to_idx.items():\n",
        "            class_dir = self.root / split / cls\n",
        "            if not class_dir.exists():\n",
        "                continue\n",
        "            for imgp in class_dir.glob(\"*.*\"):\n",
        "                if imgp.suffix.lower() in [\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"]:\n",
        "                    self.samples.append((str(imgp), idx))\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n",
        "        path, label = self.samples[idx]\n",
        "        img_bgr = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "        if img_bgr is None:\n",
        "            raise FileNotFoundError(path)\n",
        "        x = self.transform(img_bgr)\n",
        "        return x, label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training and Evaluation Functions\n",
        "\n",
        "Define functions to train the model for one epoch and to evaluate it on a dataset, computing common metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def eval_cls_metrics(model: nn.Module, loader: DataLoader, criterion: nn.Module, device: torch.device) -> Dict[str, float]:\n",
        "    \"\"\"Evaluate a classification model and compute common metrics.\"\"\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    losses = 0.0\n",
        "    nobs = 0\n",
        "    for x, y in loader:\n",
        "        x = x.to(device, non_blocking=True)\n",
        "        y = torch.as_tensor(y, dtype=torch.long, device=device)\n",
        "        with amp.autocast('cuda', dtype=torch.float16, enabled=True):\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "        losses += float(loss.item()) * x.size(0)\n",
        "        nobs += x.size(0)\n",
        "        all_preds.append(logits.argmax(1).detach().cpu().numpy())\n",
        "        all_labels.append(y.detach().cpu().numpy())\n",
        "    y_pred = np.concatenate(all_preds) if all_preds else np.array([])\n",
        "    y_true = np.concatenate(all_labels) if all_labels else np.array([])\n",
        "    val_loss = losses / max(1, nobs)\n",
        "\n",
        "    if y_true.size == 0:\n",
        "        return {\"loss\": val_loss, \"acc\": 0.0, \"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0, \"specificity\": None}\n",
        "\n",
        "    acc  = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
        "    rec  = recall_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
        "    f1   = f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
        "    cm   = confusion_matrix(y_true, y_pred)\n",
        "    spec = None\n",
        "    if cm.shape == (2, 2):\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "        spec = tn / (tn + fp + 1e-12)\n",
        "    return {\"loss\": val_loss, \"acc\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"specificity\": spec}\n",
        "\n",
        "\n",
        "def train_one_epoch_cls(model: nn.Module, loader: DataLoader, opt: torch.optim.Optimizer, criterion: nn.Module,\n",
        "                        device: torch.device, epoch: int, epochs: int) -> Tuple[float, float]:\n",
        "    \"\"\"Train the model for a single epoch and return average loss and accuracy.\"\"\"\n",
        "    model.train()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    loss_sum = 0.0\n",
        "    for x, y in loader:\n",
        "        x = x.to(device, non_blocking=True)\n",
        "        y = torch.as_tensor(y, dtype=torch.long, device=device)\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        with amp.autocast('cuda', dtype=torch.float16, enabled=True):\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "        SCALER.scale(loss).backward()\n",
        "        SCALER.step(opt)\n",
        "        SCALER.update()\n",
        "        loss_sum += float(loss.item()) * x.size(0)\n",
        "        preds = logits.argmax(1)\n",
        "        correct += int((preds == y).sum().item())\n",
        "        total += x.size(0)\n",
        "    avg_loss = loss_sum / max(1, total)\n",
        "    acc = correct / max(1, total)\n",
        "    return avg_loss, acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build ConvNeXt Model\n",
        "\n",
        "Select a ConvNeXt variant and define a helper to instantiate it with a custom dropout rate and number of classes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Choose a ConvNeXt variant: 'convnext_tiny', 'convnext_small', or 'convnext_base'\n",
        "MANUAL_CONVNEXT_VARIANT = 'convnext_tiny'\n",
        "\n",
        "def build_convnext_classifier(variant: str, num_classes: int, dropout: float) -> nn.Module:\n",
        "    \"\"\"Create a ConvNeXt model for classification using timm.\"\"\"\n",
        "    model = timm.create_model(variant, pretrained=True, num_classes=num_classes, drop_rate=dropout)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export CIFAR-10 to Train/Val/Test Folders\n",
        "\n",
        "The CIFAR-10 dataset is originally provided in a binary format.  This cell exports the dataset into a folder structure with separate `train`, `val`, and `test` splits.  The validation set is created by splitting the original test set in half.  Set `overwrite=False` to skip regeneration if the export already exists.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] CIFAR-10 not found locally. Downloading...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|                                                                               | 0.00/170M [00:00<?, ?B/s]\r  0%|▏                                                                      | 459k/170M [00:00<00:37, 4.51MB/s]\r  3%|██▎                                                                   | 5.64M/170M [00:00<00:05, 32.1MB/s]\r  6%|███▉                                                                  | 9.67M/170M [00:00<00:04, 35.8MB/s]\r  8%|█████▋                                                                | 13.9M/170M [00:00<00:04, 38.3MB/s]\r 10%|███████▎                                                              | 17.8M/170M [00:00<00:04, 35.6MB/s]\r 13%|████████▉                                                             | 21.8M/170M [00:00<00:04, 37.1MB/s]\r 15%|██████████▋                                                           | 26.0M/170M [00:00<00:03, 38.5MB/s]\r 18%|████████████▎                                                         | 29.9M/170M [00:00<00:03, 38.3MB/s]\r 20%|█████████████▉                                                        | 33.9M/170M [00:00<00:03, 38.8MB/s]\r 22%|███████████████▌                                                      | 37.8M/170M [00:01<00:03, 37.8MB/s]\r 25%|█████████████████▎                                                    | 42.2M/170M [00:01<00:03, 39.7MB/s]\r 27%|███████████████████                                                   | 46.5M/170M [00:01<00:03, 40.5MB/s]\r 30%|████████████████████▊                                                 | 50.8M/170M [00:01<00:02, 41.1MB/s]\r 32%|██████████████████████▌                                               | 54.9M/170M [00:01<00:03, 36.7MB/s]\r 35%|████████████████████████▏                                             | 58.9M/170M [00:01<00:02, 37.5MB/s]\r 37%|█████████████████████████▊                                            | 62.9M/170M [00:01<00:02, 38.3MB/s]\r 40%|███████████████████████████▋                                          | 67.4M/170M [00:01<00:02, 40.1MB/s]\r 42%|█████████████████████████████▎                                        | 71.5M/170M [00:01<00:02, 38.4MB/s]\r 44%|██████████████████████████████▉                                       | 75.4M/170M [00:02<00:02, 38.3MB/s]\r 46%|████████████████████████████████▌                                     | 79.2M/170M [00:02<00:02, 37.0MB/s]\r 49%|██████████████████████████████████▍                                   | 83.9M/170M [00:02<00:02, 39.5MB/s]\r 52%|████████████████████████████████████▏                                 | 88.2M/170M [00:02<00:02, 40.5MB/s]\r 54%|█████████████████████████████████████▉                                | 92.3M/170M [00:02<00:01, 39.6MB/s]\r 57%|███████████████████████████████████████▉                              | 97.2M/170M [00:02<00:01, 42.3MB/s]\r 60%|██████████████████████████████████████████▎                            | 101M/170M [00:02<00:01, 42.2MB/s]\r 63%|████████████████████████████████████████████▍                          | 107M/170M [00:02<00:01, 44.6MB/s]\r 65%|██████████████████████████████████████████████▎                        | 111M/170M [00:02<00:01, 43.4MB/s]\r 68%|████████████████████████████████████████████████▏                      | 116M/170M [00:02<00:01, 43.7MB/s]\r 70%|██████████████████████████████████████████████████                     | 120M/170M [00:03<00:01, 44.2MB/s]\r 73%|███████████████████████████████████████████████████▉                   | 125M/170M [00:03<00:01, 43.6MB/s]\r 76%|█████████████████████████████████████████████████████▋                 | 129M/170M [00:03<00:00, 42.8MB/s]\r 78%|███████████████████████████████████████████████████████▋               | 134M/170M [00:03<00:00, 43.8MB/s]\r 81%|█████████████████████████████████████████████████████████▌             | 138M/170M [00:03<00:00, 40.4MB/s]\r 84%|███████████████████████████████████████████████████████████▎           | 143M/170M [00:03<00:00, 41.1MB/s]\r 86%|█████████████████████████████████████████████████████████████▍         | 147M/170M [00:03<00:00, 43.3MB/s]\r 89%|███████████████████████████████████████████████████████████████▍       | 152M/170M [00:03<00:00, 44.5MB/s]\r 92%|█████████████████████████████████████████████████████████████████▎     | 157M/170M [00:03<00:00, 41.9MB/s]\r 94%|███████████████████████████████████████████████████████████████████    | 161M/170M [00:04<00:00, 42.1MB/s]\r 97%|█████████████████████████████████████████████████████████████████████  | 166M/170M [00:04<00:00, 43.1MB/s]\r100%|██████████████████████████████████████████████████████████████████████▊| 170M/170M [00:04<00:00, 37.6MB/s]\r100%|███████████████████████████████████████████████████████████████████████| 170M/170M [00:04<00:00, 39.9MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CIFAR-10 classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rExporting train:   0%|                                                               | 0/50000 [00:00<?, ?it/s]\rExporting train:   0%|▏                                                  | 145/50000 [00:00<00:34, 1442.18it/s]\rExporting train:   1%|▎                                                  | 310/50000 [00:00<00:31, 1560.08it/s]\rExporting train:   1%|▍                                                  | 467/50000 [00:00<00:32, 1513.21it/s]\rExporting train:   1%|▋                                                  | 619/50000 [00:00<00:32, 1502.98it/s]\rExporting train:   2%|▊                                                  | 779/50000 [00:00<00:32, 1534.46it/s]\rExporting train:   2%|▉                                                  | 948/50000 [00:00<00:30, 1583.83it/s]\rExporting train:   2%|█                                                 | 1117/50000 [00:00<00:30, 1617.40it/s]\rExporting train:   3%|█▎                                                | 1280/50000 [00:00<00:30, 1620.86it/s]\rExporting train:   3%|█▍                                                | 1443/50000 [00:00<00:30, 1608.03it/s]\rExporting train:   3%|█▌                                                | 1604/50000 [00:01<00:30, 1583.12it/s]\rExporting train:   4%|█▊                                                | 1773/50000 [00:01<00:29, 1614.60it/s]\rExporting train:   4%|█▉                                                | 1940/50000 [00:01<00:29, 1629.18it/s]\rExporting train:   4%|██                                                | 2112/50000 [00:01<00:28, 1654.58it/s]\rExporting train:   5%|██▎                                               | 2279/50000 [00:01<00:28, 1657.66it/s]\rExporting train:   5%|██▍                                               | 2445/50000 [00:01<00:30, 1568.46it/s]\rExporting train:   5%|██▌                                               | 2617/50000 [00:01<00:29, 1611.73it/s]\rExporting train:   6%|██▊                                               | 2795/50000 [00:01<00:28, 1659.42it/s]\rExporting train:   6%|██▉                                               | 2962/50000 [00:01<00:28, 1631.55it/s]\rExporting train:   6%|███▏                                              | 3126/50000 [00:01<00:28, 1619.10it/s]\rExporting train:   7%|███▎                                              | 3297/50000 [00:02<00:28, 1643.49it/s]\rExporting train:   7%|███▍                                              | 3475/50000 [00:02<00:27, 1682.83it/s]\rExporting train:   7%|███▋                                              | 3654/50000 [00:02<00:27, 1712.72it/s]\rExporting train:   8%|███▊                                              | 3826/50000 [00:02<00:29, 1550.40it/s]\rExporting train:   8%|███▉                                              | 3985/50000 [00:02<00:30, 1509.60it/s]\rExporting train:   8%|████▏                                             | 4139/50000 [00:02<00:31, 1475.87it/s]\rExporting train:   9%|████▎                                             | 4298/50000 [00:02<00:30, 1505.68it/s]\rExporting train:   9%|████▍                                             | 4459/50000 [00:02<00:29, 1534.98it/s]\rExporting train:   9%|████▋                                             | 4630/50000 [00:02<00:28, 1585.38it/s]\rExporting train:  10%|████▊                                             | 4790/50000 [00:03<00:29, 1515.20it/s]\rExporting train:  10%|████▉                                             | 4943/50000 [00:03<00:29, 1504.41it/s]\rExporting train:  10%|█████                                             | 5101/50000 [00:03<00:29, 1524.89it/s]\rExporting train:  11%|█████▎                                            | 5255/50000 [00:03<00:29, 1492.95it/s]\rExporting train:  11%|█████▍                                            | 5405/50000 [00:03<00:30, 1464.94it/s]\rExporting train:  11%|█████▌                                            | 5552/50000 [00:03<00:30, 1441.62it/s]\rExporting train:  11%|█████▋                                            | 5703/50000 [00:03<00:30, 1459.14it/s]\rExporting train:  12%|█████▊                                            | 5865/50000 [00:03<00:29, 1505.00it/s]\rExporting train:  12%|██████                                            | 6016/50000 [00:03<00:30, 1453.24it/s]\rExporting train:  12%|██████▏                                           | 6162/50000 [00:03<00:30, 1440.37it/s]\rExporting train:  13%|██████▎                                           | 6307/50000 [00:04<00:30, 1412.34it/s]\rExporting train:  13%|██████▍                                           | 6449/50000 [00:04<00:31, 1372.44it/s]\rExporting train:  13%|██████▌                                           | 6596/50000 [00:04<00:31, 1399.60it/s]\rExporting train:  13%|██████▋                                           | 6740/50000 [00:04<00:30, 1410.43it/s]\rExporting train:  14%|██████▉                                           | 6910/50000 [00:04<00:28, 1493.31it/s]\rExporting train:  14%|███████                                           | 7082/50000 [00:04<00:27, 1558.97it/s]\rExporting train:  15%|███████▎                                          | 7256/50000 [00:04<00:26, 1611.05it/s]\rExporting train:  15%|███████▍                                          | 7425/50000 [00:04<00:26, 1632.38it/s]\rExporting train:  15%|███████▌                                          | 7589/50000 [00:04<00:27, 1545.02it/s]\rExporting train:  15%|███████▋                                          | 7745/50000 [00:05<00:28, 1486.28it/s]\rExporting train:  16%|███████▉                                          | 7895/50000 [00:05<00:28, 1460.80it/s]\rExporting train:  16%|████████                                          | 8045/50000 [00:05<00:28, 1469.94it/s]\rExporting train:  16%|████████▏                                         | 8214/50000 [00:05<00:27, 1531.68it/s]\rExporting train:  17%|████████▍                                         | 8379/50000 [00:05<00:26, 1566.10it/s]\rExporting train:  17%|████████▌                                         | 8550/50000 [00:05<00:25, 1607.28it/s]\rExporting train:  17%|████████▋                                         | 8726/50000 [00:05<00:25, 1650.49it/s]\rExporting train:  18%|████████▉                                         | 8892/50000 [00:05<00:25, 1611.25it/s]\rExporting train:  18%|█████████                                         | 9054/50000 [00:05<00:25, 1598.05it/s]\rExporting train:  18%|█████████▏                                        | 9215/50000 [00:05<00:26, 1534.33it/s]\rExporting train:  19%|█████████▎                                        | 9370/50000 [00:06<00:27, 1492.86it/s]\rExporting train:  19%|█████████▌                                        | 9536/50000 [00:06<00:26, 1537.53it/s]\rExporting train:  19%|█████████▋                                        | 9700/50000 [00:06<00:25, 1564.18it/s]\rExporting train:  20%|█████████▊                                        | 9869/50000 [00:06<00:25, 1600.76it/s]\rExporting train:  20%|█████████▊                                       | 10037/50000 [00:06<00:24, 1623.74it/s]\rExporting train:  20%|█████████▉                                       | 10200/50000 [00:06<00:25, 1570.28it/s]\rExporting train:  21%|██████████▏                                      | 10358/50000 [00:06<00:25, 1548.19it/s]\rExporting train:  21%|██████████▎                                      | 10532/50000 [00:06<00:24, 1602.83it/s]\rExporting train:  21%|██████████▍                                      | 10705/50000 [00:06<00:23, 1639.20it/s]\rExporting train:  22%|██████████▋                                      | 10870/50000 [00:07<00:25, 1554.56it/s]\rExporting train:  22%|██████████▊                                      | 11027/50000 [00:07<00:26, 1467.94it/s]\rExporting train:  22%|██████████▉                                      | 11187/50000 [00:07<00:25, 1503.86it/s]\rExporting train:  23%|███████████                                      | 11339/50000 [00:07<00:26, 1457.55it/s]\rExporting train:  23%|███████████▎                                     | 11486/50000 [00:07<00:26, 1438.50it/s]\rExporting train:  23%|███████████▍                                     | 11631/50000 [00:07<00:27, 1412.94it/s]\rExporting train:  24%|███████████▌                                     | 11781/50000 [00:07<00:26, 1434.59it/s]\rExporting train:  24%|███████████▋                                     | 11943/50000 [00:07<00:25, 1487.90it/s]\rExporting train:  24%|███████████▊                                     | 12116/50000 [00:07<00:24, 1557.24it/s]\rExporting train:  25%|████████████                                     | 12279/50000 [00:07<00:23, 1577.70it/s]\rExporting train:  25%|████████████▏                                    | 12443/50000 [00:08<00:23, 1593.78it/s]\rExporting train:  25%|████████████▎                                    | 12604/50000 [00:08<00:23, 1597.60it/s]\rExporting train:  26%|████████████▌                                    | 12774/50000 [00:08<00:22, 1627.32it/s]\rExporting train:  26%|████████████▋                                    | 12947/50000 [00:08<00:22, 1656.49it/s]\rExporting train:  26%|████████████▊                                    | 13115/50000 [00:08<00:22, 1660.28it/s]\rExporting train:  27%|█████████████                                    | 13282/50000 [00:08<00:23, 1596.16it/s]\rExporting train:  27%|█████████████▏                                   | 13443/50000 [00:08<00:23, 1526.65it/s]\rExporting train:  27%|█████████████▎                                   | 13603/50000 [00:08<00:23, 1546.17it/s]\rExporting train:  28%|█████████████▌                                   | 13776/50000 [00:08<00:22, 1597.52it/s]\rExporting train:  28%|█████████████▋                                   | 13937/50000 [00:08<00:23, 1565.27it/s]\rExporting train:  28%|█████████████▊                                   | 14095/50000 [00:09<00:23, 1514.96it/s]\rExporting train:  28%|█████████████▉                                   | 14248/50000 [00:09<00:23, 1495.25it/s]\rExporting train:  29%|██████████████                                   | 14398/50000 [00:09<00:24, 1447.63it/s]\rExporting train:  29%|██████████████▎                                  | 14544/50000 [00:09<00:24, 1441.01it/s]\rExporting train:  29%|██████████████▍                                  | 14701/50000 [00:09<00:23, 1476.31it/s]\rExporting train:  30%|██████████████▌                                  | 14878/50000 [00:09<00:22, 1559.35it/s]\rExporting train:  30%|██████████████▊                                  | 15057/50000 [00:09<00:21, 1625.09it/s]\rExporting train:  30%|██████████████▉                                  | 15228/50000 [00:09<00:21, 1648.14it/s]\rExporting train:  31%|███████████████                                  | 15394/50000 [00:09<00:21, 1640.07it/s]\rExporting train:  31%|███████████████▏                                 | 15559/50000 [00:10<00:21, 1636.42it/s]\rExporting train:  31%|███████████████▍                                 | 15723/50000 [00:10<00:21, 1572.07it/s]\rExporting train:  32%|███████████████▌                                 | 15881/50000 [00:10<00:23, 1471.28it/s]\rExporting train:  32%|███████████████▋                                 | 16035/50000 [00:10<00:22, 1489.69it/s]\rExporting train:  32%|███████████████▊                                 | 16196/50000 [00:10<00:22, 1521.22it/s]\rExporting train:  33%|████████████████                                 | 16350/50000 [00:10<00:22, 1475.23it/s]\rExporting train:  33%|████████████████▏                                | 16499/50000 [00:10<00:23, 1427.50it/s]\rExporting train:  33%|████████████████▎                                | 16658/50000 [00:10<00:22, 1473.19it/s]\rExporting train:  34%|████████████████▍                                | 16808/50000 [00:10<00:22, 1480.06it/s]\rExporting train:  34%|████████████████▌                                | 16957/50000 [00:11<00:22, 1447.48it/s]\rExporting train:  34%|████████████████▊                                | 17103/50000 [00:11<00:22, 1434.33it/s]\rExporting train:  35%|████████████████▉                                | 17255/50000 [00:11<00:22, 1457.21it/s]\rExporting train:  35%|█████████████████                                | 17402/50000 [00:11<00:22, 1440.42it/s]\rExporting train:  35%|█████████████████▏                               | 17547/50000 [00:11<00:23, 1394.62it/s]\rExporting train:  35%|█████████████████▎                               | 17703/50000 [00:11<00:22, 1441.17it/s]\rExporting train:  36%|█████████████████▍                               | 17850/50000 [00:11<00:22, 1447.31it/s]\rExporting train:  36%|█████████████████▋                               | 18022/50000 [00:11<00:20, 1525.48it/s]\rExporting train:  36%|█████████████████▊                               | 18192/50000 [00:11<00:20, 1576.31it/s]\rExporting train:  37%|██████████████████                               | 18378/50000 [00:11<00:19, 1659.36it/s]\rExporting train:  37%|██████████████████▏                              | 18545/50000 [00:12<00:19, 1652.03it/s]\rExporting train:  37%|██████████████████▎                              | 18719/50000 [00:12<00:18, 1676.40it/s]\rExporting train:  38%|██████████████████▌                              | 18892/50000 [00:12<00:18, 1690.73it/s]\rExporting train:  38%|██████████████████▋                              | 19067/50000 [00:12<00:18, 1706.74it/s]\rExporting train:  38%|██████████████████▊                              | 19238/50000 [00:12<00:18, 1690.50it/s]\rExporting train:  39%|███████████████████                              | 19408/50000 [00:12<00:18, 1651.89it/s]\rExporting train:  39%|███████████████████▏                             | 19574/50000 [00:12<00:19, 1574.13it/s]\rExporting train:  39%|███████████████████▎                             | 19741/50000 [00:12<00:18, 1600.16it/s]\rExporting train:  40%|███████████████████▌                             | 19902/50000 [00:12<00:19, 1557.48it/s]\rExporting train:  40%|███████████████████▋                             | 20067/50000 [00:12<00:18, 1581.74it/s]\rExporting train:  40%|███████████████████▊                             | 20249/50000 [00:13<00:18, 1648.90it/s]\rExporting train:  41%|████████████████████                             | 20427/50000 [00:13<00:17, 1686.26it/s]\rExporting train:  41%|████████████████████▏                            | 20599/50000 [00:13<00:17, 1694.14it/s]\rExporting train:  42%|████████████████████▎                            | 20775/50000 [00:13<00:17, 1711.78it/s]\rExporting train:  42%|████████████████████▌                            | 20950/50000 [00:13<00:16, 1721.72it/s]\rExporting train:  42%|████████████████████▋                            | 21126/50000 [00:13<00:16, 1732.39it/s]\rExporting train:  43%|████████████████████▊                            | 21300/50000 [00:13<00:16, 1731.81it/s]\rExporting train:  43%|█████████████████████                            | 21474/50000 [00:13<00:16, 1721.77it/s]\rExporting train:  43%|█████████████████████▏                           | 21647/50000 [00:13<00:16, 1721.89it/s]\rExporting train:  44%|█████████████████████▍                           | 21820/50000 [00:13<00:16, 1716.78it/s]\rExporting train:  44%|█████████████████████▌                           | 21998/50000 [00:14<00:16, 1735.35it/s]\rExporting train:  44%|█████████████████████▋                           | 22172/50000 [00:14<00:16, 1728.85it/s]\rExporting train:  45%|█████████████████████▉                           | 22356/50000 [00:14<00:15, 1761.39it/s]\rExporting train:  45%|██████████████████████                           | 22537/50000 [00:14<00:15, 1775.38it/s]\rExporting train:  45%|██████████████████████▎                          | 22715/50000 [00:14<00:15, 1763.34it/s]\rExporting train:  46%|██████████████████████▍                          | 22892/50000 [00:14<00:15, 1696.73it/s]\rExporting train:  46%|██████████████████████▌                          | 23063/50000 [00:14<00:15, 1699.09it/s]\rExporting train:  46%|██████████████████████▊                          | 23234/50000 [00:14<00:16, 1630.03it/s]\rExporting train:  47%|██████████████████████▉                          | 23398/50000 [00:14<00:16, 1588.09it/s]\rExporting train:  47%|███████████████████████                          | 23558/50000 [00:15<00:17, 1491.66it/s]\rExporting train:  47%|███████████████████████▏                         | 23709/50000 [00:15<00:18, 1433.63it/s]\rExporting train:  48%|███████████████████████▍                         | 23854/50000 [00:15<00:18, 1425.31it/s]\rExporting train:  48%|███████████████████████▌                         | 23998/50000 [00:15<00:18, 1411.05it/s]\rExporting train:  48%|███████████████████████▋                         | 24141/50000 [00:15<00:18, 1415.54it/s]\rExporting train:  49%|███████████████████████▊                         | 24287/50000 [00:15<00:18, 1427.78it/s]\rExporting train:  49%|███████████████████████▉                         | 24431/50000 [00:15<00:17, 1429.83it/s]\rExporting train:  49%|████████████████████████                         | 24583/50000 [00:15<00:17, 1453.47it/s]\rExporting train:  49%|████████████████████████▏                        | 24729/50000 [00:15<00:17, 1413.30it/s]\rExporting train:  50%|████████████████████████▍                        | 24894/50000 [00:15<00:16, 1480.58it/s]\rExporting train:  50%|████████████████████████▌                        | 25043/50000 [00:16<00:17, 1432.01it/s]\rExporting train:  50%|████████████████████████▋                        | 25190/50000 [00:16<00:17, 1442.76it/s]\rExporting train:  51%|████████████████████████▊                        | 25335/50000 [00:16<00:17, 1439.69it/s]\rExporting train:  51%|████████████████████████▉                        | 25480/50000 [00:16<00:17, 1412.39it/s]\rExporting train:  51%|█████████████████████████▏                       | 25638/50000 [00:16<00:16, 1460.44it/s]\rExporting train:  52%|█████████████████████████▎                       | 25802/50000 [00:16<00:16, 1510.39it/s]\rExporting train:  52%|█████████████████████████▍                       | 25972/50000 [00:16<00:15, 1564.91it/s]\rExporting train:  52%|█████████████████████████▌                       | 26145/50000 [00:16<00:14, 1613.15it/s]\rExporting train:  53%|█████████████████████████▊                       | 26313/50000 [00:16<00:14, 1631.44it/s]\rExporting train:  53%|█████████████████████████▉                       | 26495/50000 [00:17<00:13, 1685.51it/s]\rExporting train:  53%|██████████████████████████▏                      | 26664/50000 [00:17<00:14, 1644.26it/s]\rExporting train:  54%|██████████████████████████▎                      | 26834/50000 [00:17<00:13, 1658.76it/s]\rExporting train:  54%|██████████████████████████▍                      | 27001/50000 [00:17<00:14, 1611.80it/s]\rExporting train:  54%|██████████████████████████▌                      | 27163/50000 [00:17<00:14, 1562.00it/s]\rExporting train:  55%|██████████████████████████▊                      | 27320/50000 [00:17<00:15, 1485.84it/s]\rExporting train:  55%|██████████████████████████▉                      | 27471/50000 [00:17<00:15, 1491.50it/s]\rExporting train:  55%|███████████████████████████                      | 27621/50000 [00:17<00:15, 1430.68it/s]\rExporting train:  56%|███████████████████████████▏                     | 27765/50000 [00:17<00:15, 1427.36it/s]\rExporting train:  56%|███████████████████████████▎                     | 27909/50000 [00:17<00:15, 1413.32it/s]\rExporting train:  56%|███████████████████████████▍                     | 28057/50000 [00:18<00:15, 1430.60it/s]\rExporting train:  56%|███████████████████████████▋                     | 28203/50000 [00:18<00:15, 1438.35it/s]\rExporting train:  57%|███████████████████████████▊                     | 28376/50000 [00:18<00:14, 1522.48it/s]\rExporting train:  57%|███████████████████████████▉                     | 28547/50000 [00:18<00:13, 1575.70it/s]\rExporting train:  57%|████████████████████████████▏                    | 28717/50000 [00:18<00:13, 1611.51it/s]\rExporting train:  58%|████████████████████████████▎                    | 28889/50000 [00:18<00:12, 1641.56it/s]\rExporting train:  58%|████████████████████████████▍                    | 29055/50000 [00:18<00:12, 1646.93it/s]\rExporting train:  58%|████████████████████████████▋                    | 29220/50000 [00:18<00:12, 1602.91it/s]\rExporting train:  59%|████████████████████████████▊                    | 29392/50000 [00:18<00:12, 1635.93it/s]\rExporting train:  59%|████████████████████████████▉                    | 29578/50000 [00:18<00:12, 1699.61it/s]\rExporting train:  59%|█████████████████████████████▏                   | 29749/50000 [00:19<00:12, 1679.34it/s]\rExporting train:  60%|█████████████████████████████▎                   | 29918/50000 [00:19<00:12, 1616.93it/s]\rExporting train:  60%|█████████████████████████████▍                   | 30084/50000 [00:19<00:12, 1628.43it/s]\rExporting train:  61%|█████████████████████████████▋                   | 30265/50000 [00:19<00:11, 1681.27it/s]\rExporting train:  61%|█████████████████████████████▊                   | 30434/50000 [00:19<00:11, 1673.04it/s]\rExporting train:  61%|█████████████████████████████▉                   | 30602/50000 [00:19<00:12, 1604.56it/s]\rExporting train:  62%|██████████████████████████████▏                  | 30764/50000 [00:19<00:12, 1572.04it/s]\rExporting train:  62%|██████████████████████████████▎                  | 30928/50000 [00:19<00:11, 1589.97it/s]\rExporting train:  62%|██████████████████████████████▍                  | 31101/50000 [00:19<00:11, 1629.09it/s]\rExporting train:  63%|██████████████████████████████▋                  | 31265/50000 [00:20<00:11, 1631.77it/s]\rExporting train:  63%|██████████████████████████████▊                  | 31441/50000 [00:20<00:11, 1668.50it/s]\rExporting train:  63%|██████████████████████████████▉                  | 31615/50000 [00:20<00:10, 1688.24it/s]\rExporting train:  64%|███████████████████████████████▏                 | 31800/50000 [00:20<00:10, 1736.20it/s]\rExporting train:  64%|███████████████████████████████▎                 | 31983/50000 [00:20<00:10, 1763.83it/s]\rExporting train:  64%|███████████████████████████████▌                 | 32160/50000 [00:20<00:10, 1669.00it/s]\rExporting train:  65%|███████████████████████████████▋                 | 32329/50000 [00:20<00:10, 1643.90it/s]\rExporting train:  65%|███████████████████████████████▊                 | 32495/50000 [00:20<00:10, 1611.78it/s]\rExporting train:  65%|████████████████████████████████                 | 32657/50000 [00:20<00:10, 1591.41it/s]\rExporting train:  66%|████████████████████████████████▏                | 32817/50000 [00:20<00:11, 1543.18it/s]\rExporting train:  66%|████████████████████████████████▎                | 32972/50000 [00:21<00:11, 1540.68it/s]\rExporting train:  66%|████████████████████████████████▍                | 33145/50000 [00:21<00:10, 1593.05it/s]\rExporting train:  67%|████████████████████████████████▋                | 33318/50000 [00:21<00:10, 1632.90it/s]\rExporting train:  67%|████████████████████████████████▊                | 33482/50000 [00:21<00:10, 1620.84it/s]\rExporting train:  67%|████████████████████████████████▉                | 33649/50000 [00:21<00:10, 1633.68it/s]\rExporting train:  68%|█████████████████████████████████▏               | 33813/50000 [00:21<00:09, 1632.55it/s]\rExporting train:  68%|█████████████████████████████████▎               | 33977/50000 [00:21<00:10, 1577.92it/s]\rExporting train:  68%|█████████████████████████████████▍               | 34136/50000 [00:21<00:10, 1567.00it/s]\rExporting train:  69%|█████████████████████████████████▌               | 34301/50000 [00:21<00:09, 1588.96it/s]\rExporting train:  69%|█████████████████████████████████▊               | 34461/50000 [00:22<00:09, 1578.46it/s]\rExporting train:  69%|█████████████████████████████████▉               | 34620/50000 [00:22<00:09, 1558.39it/s]\rExporting train:  70%|██████████████████████████████████               | 34780/50000 [00:22<00:09, 1569.74it/s]\rExporting train:  70%|██████████████████████████████████▏              | 34938/50000 [00:22<00:09, 1571.89it/s]\rExporting train:  70%|██████████████████████████████████▍              | 35097/50000 [00:22<00:09, 1574.67it/s]\rExporting train:  71%|██████████████████████████████████▌              | 35262/50000 [00:22<00:09, 1596.36it/s]\rExporting train:  71%|██████████████████████████████████▋              | 35425/50000 [00:22<00:09, 1605.07it/s]\rExporting train:  71%|██████████████████████████████████▊              | 35586/50000 [00:22<00:08, 1603.08it/s]\rExporting train:  71%|███████████████████████████████████              | 35747/50000 [00:22<00:09, 1580.93it/s]\rExporting train:  72%|███████████████████████████████████▏             | 35906/50000 [00:22<00:08, 1577.09it/s]\rExporting train:  72%|███████████████████████████████████▎             | 36068/50000 [00:23<00:08, 1588.71it/s]\rExporting train:  73%|███████████████████████████████████▌             | 36261/50000 [00:23<00:08, 1687.53it/s]\rExporting train:  73%|███████████████████████████████████▋             | 36440/50000 [00:23<00:07, 1716.35it/s]\rExporting train:  73%|███████████████████████████████████▉             | 36617/50000 [00:23<00:07, 1729.80it/s]\rExporting train:  74%|████████████████████████████████████             | 36791/50000 [00:23<00:07, 1672.87it/s]\rExporting train:  74%|████████████████████████████████████▏            | 36964/50000 [00:23<00:07, 1687.30it/s]\rExporting train:  74%|████████████████████████████████████▍            | 37134/50000 [00:23<00:07, 1686.24it/s]\rExporting train:  75%|████████████████████████████████████▌            | 37303/50000 [00:23<00:07, 1667.68it/s]\rExporting train:  75%|████████████████████████████████████▋            | 37475/50000 [00:23<00:07, 1682.04it/s]\rExporting train:  75%|████████████████████████████████████▉            | 37644/50000 [00:23<00:07, 1664.39it/s]\rExporting train:  76%|█████████████████████████████████████            | 37811/50000 [00:24<00:07, 1634.87it/s]\rExporting train:  76%|█████████████████████████████████████▏           | 37975/50000 [00:24<00:07, 1633.78it/s]\rExporting train:  76%|█████████████████████████████████████▍           | 38139/50000 [00:24<00:07, 1615.02it/s]\rExporting train:  77%|█████████████████████████████████████▌           | 38302/50000 [00:24<00:07, 1618.00it/s]\rExporting train:  77%|█████████████████████████████████████▋           | 38464/50000 [00:24<00:07, 1610.62it/s]\rExporting train:  77%|█████████████████████████████████████▊           | 38626/50000 [00:24<00:07, 1610.03it/s]\rExporting train:  78%|██████████████████████████████████████           | 38788/50000 [00:24<00:07, 1599.71it/s]\rExporting train:  78%|██████████████████████████████████████▏          | 38949/50000 [00:24<00:06, 1582.16it/s]\rExporting train:  78%|██████████████████████████████████████▎          | 39117/50000 [00:24<00:06, 1609.28it/s]\rExporting train:  79%|██████████████████████████████████████▌          | 39299/50000 [00:24<00:06, 1671.08it/s]\rExporting train:  79%|██████████████████████████████████████▋          | 39467/50000 [00:25<00:06, 1655.06it/s]\rExporting train:  79%|██████████████████████████████████████▊          | 39633/50000 [00:25<00:06, 1640.52it/s]\rExporting train:  80%|███████████████████████████████████████          | 39798/50000 [00:25<00:06, 1600.20it/s]\rExporting train:  80%|███████████████████████████████████████▏         | 39959/50000 [00:25<00:06, 1546.03it/s]\rExporting train:  80%|███████████████████████████████████████▎         | 40115/50000 [00:25<00:06, 1526.40it/s]\rExporting train:  81%|███████████████████████████████████████▍         | 40276/50000 [00:25<00:06, 1548.86it/s]\rExporting train:  81%|███████████████████████████████████████▌         | 40432/50000 [00:25<00:06, 1530.38it/s]\rExporting train:  81%|███████████████████████████████████████▊         | 40587/50000 [00:25<00:06, 1533.86it/s]\rExporting train:  81%|███████████████████████████████████████▉         | 40746/50000 [00:25<00:05, 1548.46it/s]\rExporting train:  82%|████████████████████████████████████████         | 40905/50000 [00:26<00:05, 1552.20it/s]\rExporting train:  82%|████████████████████████████████████████▏        | 41061/50000 [00:26<00:05, 1515.11it/s]\rExporting train:  82%|████████████████████████████████████████▍        | 41217/50000 [00:26<00:05, 1526.33it/s]\rExporting train:  83%|████████████████████████████████████████▌        | 41376/50000 [00:26<00:05, 1543.25it/s]\rExporting train:  83%|████████████████████████████████████████▋        | 41531/50000 [00:26<00:05, 1540.93it/s]\rExporting train:  83%|████████████████████████████████████████▊        | 41686/50000 [00:26<00:05, 1510.78it/s]\rExporting train:  84%|█████████████████████████████████████████        | 41838/50000 [00:26<00:05, 1472.89it/s]\rExporting train:  84%|█████████████████████████████████████████▏       | 41986/50000 [00:26<00:05, 1425.64it/s]\rExporting train:  84%|█████████████████████████████████████████▎       | 42130/50000 [00:26<00:05, 1427.99it/s]\rExporting train:  85%|█████████████████████████████████████████▍       | 42274/50000 [00:26<00:05, 1422.36it/s]\rExporting train:  85%|█████████████████████████████████████████▌       | 42422/50000 [00:27<00:05, 1438.70it/s]\rExporting train:  85%|█████████████████████████████████████████▋       | 42591/50000 [00:27<00:04, 1509.86it/s]\rExporting train:  86%|█████████████████████████████████████████▉       | 42755/50000 [00:27<00:04, 1545.50it/s]\rExporting train:  86%|██████████████████████████████████████████       | 42919/50000 [00:27<00:04, 1571.80it/s]\rExporting train:  86%|██████████████████████████████████████████▏      | 43077/50000 [00:27<00:04, 1484.82it/s]\rExporting train:  86%|██████████████████████████████████████████▎      | 43227/50000 [00:27<00:04, 1460.20it/s]\rExporting train:  87%|██████████████████████████████████████████▌      | 43374/50000 [00:27<00:04, 1457.89it/s]\rExporting train:  87%|██████████████████████████████████████████▋      | 43521/50000 [00:27<00:04, 1406.30it/s]\rExporting train:  87%|██████████████████████████████████████████▊      | 43676/50000 [00:27<00:04, 1446.86it/s]\rExporting train:  88%|██████████████████████████████████████████▉      | 43822/50000 [00:27<00:04, 1442.18it/s]\rExporting train:  88%|███████████████████████████████████████████      | 43967/50000 [00:28<00:04, 1430.62it/s]\rExporting train:  88%|███████████████████████████████████████████▏     | 44115/50000 [00:28<00:04, 1443.67it/s]\rExporting train:  89%|███████████████████████████████████████████▍     | 44267/50000 [00:28<00:03, 1463.67it/s]\rExporting train:  89%|███████████████████████████████████████████▌     | 44415/50000 [00:28<00:03, 1467.37it/s]\rExporting train:  89%|███████████████████████████████████████████▋     | 44565/50000 [00:28<00:03, 1476.69it/s]\rExporting train:  89%|███████████████████████████████████████████▊     | 44723/50000 [00:28<00:03, 1504.99it/s]\rExporting train:  90%|███████████████████████████████████████████▉     | 44888/50000 [00:28<00:03, 1546.50it/s]\rExporting train:  90%|████████████████████████████████████████████▏    | 45044/50000 [00:28<00:03, 1550.49it/s]\rExporting train:  90%|████████████████████████████████████████████▎    | 45210/50000 [00:28<00:03, 1582.58it/s]\rExporting train:  91%|████████████████████████████████████████████▍    | 45369/50000 [00:29<00:02, 1553.80it/s]\rExporting train:  91%|████████████████████████████████████████████▌    | 45525/50000 [00:29<00:03, 1478.38it/s]\rExporting train:  91%|████████████████████████████████████████████▊    | 45674/50000 [00:29<00:02, 1454.21it/s]\rExporting train:  92%|████████████████████████████████████████████▉    | 45823/50000 [00:29<00:02, 1464.36it/s]\rExporting train:  92%|█████████████████████████████████████████████    | 45978/50000 [00:29<00:02, 1486.34it/s]\rExporting train:  92%|█████████████████████████████████████████████▏   | 46128/50000 [00:29<00:02, 1457.83it/s]\rExporting train:  93%|█████████████████████████████████████████████▎   | 46275/50000 [00:29<00:02, 1419.84it/s]\rExporting train:  93%|█████████████████████████████████████████████▍   | 46418/50000 [00:29<00:02, 1404.75it/s]\rExporting train:  93%|█████████████████████████████████████████████▋   | 46579/50000 [00:29<00:02, 1461.93it/s]\rExporting train:  93%|█████████████████████████████████████████████▊   | 46726/50000 [00:29<00:02, 1451.70it/s]\rExporting train:  94%|█████████████████████████████████████████████▉   | 46874/50000 [00:30<00:02, 1458.43it/s]\rExporting train:  94%|██████████████████████████████████████████████   | 47044/50000 [00:30<00:01, 1527.82it/s]\rExporting train:  94%|██████████████████████████████████████████████▎  | 47213/50000 [00:30<00:01, 1573.82it/s]\rExporting train:  95%|██████████████████████████████████████████████▍  | 47375/50000 [00:30<00:01, 1585.91it/s]\rExporting train:  95%|██████████████████████████████████████████████▌  | 47543/50000 [00:30<00:01, 1613.11it/s]\rExporting train:  95%|██████████████████████████████████████████████▊  | 47705/50000 [00:30<00:01, 1586.56it/s]\rExporting train:  96%|██████████████████████████████████████████████▉  | 47880/50000 [00:30<00:01, 1634.00it/s]\rExporting train:  96%|███████████████████████████████████████████████  | 48044/50000 [00:30<00:01, 1525.29it/s]\rExporting train:  96%|███████████████████████████████████████████████▏ | 48205/50000 [00:30<00:01, 1547.64it/s]\rExporting train:  97%|███████████████████████████████████████████████▍ | 48361/50000 [00:31<00:01, 1482.01it/s]\rExporting train:  97%|███████████████████████████████████████████████▌ | 48511/50000 [00:31<00:01, 1470.89it/s]\rExporting train:  97%|███████████████████████████████████████████████▋ | 48659/50000 [00:31<00:00, 1417.75it/s]\rExporting train:  98%|███████████████████████████████████████████████▊ | 48802/50000 [00:31<00:00, 1367.93it/s]\rExporting train:  98%|███████████████████████████████████████████████▉ | 48959/50000 [00:31<00:00, 1423.22it/s]\rExporting train:  98%|████████████████████████████████████████████████▏| 49116/50000 [00:31<00:00, 1463.07it/s]\rExporting train:  99%|████████████████████████████████████████████████▎| 49270/50000 [00:31<00:00, 1484.79it/s]\rExporting train:  99%|████████████████████████████████████████████████▍| 49420/50000 [00:31<00:00, 1468.00it/s]\rExporting train:  99%|████████████████████████████████████████████████▌| 49568/50000 [00:31<00:00, 1469.94it/s]\rExporting train:  99%|████████████████████████████████████████████████▋| 49735/50000 [00:31<00:00, 1526.89it/s]\rExporting train: 100%|████████████████████████████████████████████████▉| 49889/50000 [00:32<00:00, 1485.22it/s]\rExporting train: 100%|█████████████████████████████████████████████████| 50000/50000 [00:32<00:00, 1556.02it/s]\n",
            "\rExporting val:   0%|                                                                  | 0/5000 [00:00<?, ?it/s]\rExporting val:   3%|█▊                                                    | 167/5000 [00:00<00:02, 1667.78it/s]\rExporting val:   7%|███▋                                                  | 336/5000 [00:00<00:02, 1677.89it/s]\rExporting val:  10%|█████▍                                                | 504/5000 [00:00<00:02, 1663.92it/s]\rExporting val:  14%|███████▍                                              | 684/5000 [00:00<00:02, 1714.98it/s]\rExporting val:  17%|█████████▎                                            | 861/5000 [00:00<00:02, 1733.97it/s]\rExporting val:  21%|██████████▉                                          | 1035/5000 [00:00<00:02, 1716.48it/s]\rExporting val:  24%|████████████▊                                        | 1207/5000 [00:00<00:02, 1624.47it/s]\rExporting val:  27%|██████████████▌                                      | 1371/5000 [00:00<00:02, 1591.42it/s]\rExporting val:  31%|████████████████▍                                    | 1548/5000 [00:00<00:02, 1642.53it/s]\rExporting val:  35%|██████████████████▎                                  | 1726/5000 [00:01<00:01, 1681.98it/s]\rExporting val:  38%|████████████████████▏                                | 1899/5000 [00:01<00:01, 1695.18it/s]\rExporting val:  42%|██████████████████████                               | 2076/5000 [00:01<00:01, 1717.52it/s]\rExporting val:  45%|███████████████████████▊                             | 2249/5000 [00:01<00:01, 1717.00it/s]\rExporting val:  48%|█████████████████████████▋                           | 2421/5000 [00:01<00:01, 1654.56it/s]\rExporting val:  52%|███████████████████████████▍                         | 2588/5000 [00:01<00:01, 1580.48it/s]\rExporting val:  55%|█████████████████████████████▏                       | 2748/5000 [00:01<00:01, 1535.01it/s]\rExporting val:  58%|██████████████████████████████▊                      | 2905/5000 [00:01<00:01, 1542.32it/s]\rExporting val:  62%|████████████████████████████████▋                    | 3080/5000 [00:01<00:01, 1600.24it/s]\rExporting val:  65%|██████████████████████████████████▍                  | 3245/5000 [00:01<00:01, 1613.41it/s]\rExporting val:  68%|████████████████████████████████████▏                | 3414/5000 [00:02<00:00, 1635.11it/s]\rExporting val:  72%|██████████████████████████████████████               | 3590/5000 [00:02<00:00, 1670.98it/s]\rExporting val:  75%|███████████████████████████████████████▉             | 3771/5000 [00:02<00:00, 1710.68it/s]\rExporting val:  79%|█████████████████████████████████████████▊           | 3943/5000 [00:02<00:00, 1705.81it/s]\rExporting val:  82%|███████████████████████████████████████████▌         | 4114/5000 [00:02<00:00, 1667.10it/s]\rExporting val:  86%|█████████████████████████████████████████████▍       | 4282/5000 [00:02<00:00, 1596.76it/s]\rExporting val:  89%|███████████████████████████████████████████████      | 4443/5000 [00:02<00:00, 1533.02it/s]\rExporting val:  92%|████████████████████████████████████████████████▋    | 4598/5000 [00:02<00:00, 1492.13it/s]\rExporting val:  95%|██████████████████████████████████████████████████▎  | 4748/5000 [00:02<00:00, 1452.22it/s]\rExporting val:  98%|███████████████████████████████████████████████████▉ | 4894/5000 [00:03<00:00, 1431.91it/s]\rExporting val: 100%|█████████████████████████████████████████████████████| 5000/5000 [00:03<00:00, 1608.11it/s]\n",
            "\rExporting test:   0%|                                                                 | 0/5000 [00:00<?, ?it/s]\rExporting test:   3%|█▋                                                   | 164/5000 [00:00<00:02, 1635.37it/s]\rExporting test:   7%|███▌                                                 | 341/5000 [00:00<00:02, 1711.41it/s]\rExporting test:  10%|█████▍                                               | 513/5000 [00:00<00:02, 1586.68it/s]\rExporting test:  13%|███████▏                                             | 673/5000 [00:00<00:02, 1560.30it/s]\rExporting test:  17%|████████▊                                            | 830/5000 [00:00<00:02, 1511.49it/s]\rExporting test:  20%|██████████▍                                          | 982/5000 [00:00<00:02, 1468.42it/s]\rExporting test:  23%|███████████▊                                        | 1130/5000 [00:00<00:02, 1407.98it/s]\rExporting test:  25%|█████████████▏                                      | 1272/5000 [00:00<00:02, 1393.82it/s]\rExporting test:  28%|██████████████▋                                     | 1412/5000 [00:00<00:02, 1338.86it/s]\rExporting test:  31%|████████████████                                    | 1547/5000 [00:01<00:02, 1305.21it/s]\rExporting test:  34%|█████████████████▌                                  | 1691/5000 [00:01<00:02, 1342.33it/s]\rExporting test:  37%|███████████████████                                 | 1834/5000 [00:01<00:02, 1367.62it/s]\rExporting test:  40%|████████████████████▌                               | 1980/5000 [00:01<00:02, 1394.56it/s]\rExporting test:  42%|██████████████████████                              | 2120/5000 [00:01<00:02, 1367.29it/s]\rExporting test:  45%|███████████████████████▌                            | 2269/5000 [00:01<00:01, 1400.76it/s]\rExporting test:  48%|█████████████████████████                           | 2410/5000 [00:01<00:01, 1314.95it/s]\rExporting test:  51%|██████████████████████████▍                         | 2548/5000 [00:01<00:01, 1332.72it/s]\rExporting test:  54%|████████████████████████████                        | 2696/5000 [00:01<00:01, 1374.55it/s]\rExporting test:  57%|█████████████████████████████▋                      | 2849/5000 [00:02<00:01, 1419.15it/s]\rExporting test:  60%|███████████████████████████████                     | 2992/5000 [00:02<00:01, 1414.54it/s]\rExporting test:  63%|████████████████████████████████▌                   | 3134/5000 [00:02<00:01, 1348.49it/s]\rExporting test:  66%|██████████████████████████████████                  | 3277/5000 [00:02<00:01, 1371.28it/s]\rExporting test:  69%|███████████████████████████████████▋                | 3428/5000 [00:02<00:01, 1410.39it/s]\rExporting test:  71%|█████████████████████████████████████▏              | 3570/5000 [00:02<00:01, 1402.29it/s]\rExporting test:  74%|██████████████████████████████████████▌             | 3711/5000 [00:02<00:00, 1395.93it/s]\rExporting test:  77%|████████████████████████████████████████            | 3851/5000 [00:02<00:00, 1389.51it/s]\rExporting test:  80%|█████████████████████████████████████████▋          | 4010/5000 [00:02<00:00, 1447.78it/s]\rExporting test:  83%|███████████████████████████████████████████▏        | 4157/5000 [00:02<00:00, 1452.50it/s]\rExporting test:  86%|████████████████████████████████████████████▊       | 4304/5000 [00:03<00:00, 1456.68it/s]\rExporting test:  89%|██████████████████████████████████████████████▎     | 4458/5000 [00:03<00:00, 1479.91it/s]\rExporting test:  92%|███████████████████████████████████████████████▉    | 4607/5000 [00:03<00:00, 1439.69it/s]\rExporting test:  95%|█████████████████████████████████████████████████▌  | 4760/5000 [00:03<00:00, 1465.57it/s]\rExporting test:  99%|███████████████████████████████████████████████████▎| 4933/5000 [00:03<00:00, 1542.09it/s]\rExporting test: 100%|████████████████████████████████████████████████████| 5000/5000 [00:03<00:00, 1430.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DONE] CIFAR-10 exported to: /root/data/cifar10_extracted\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# CIFAR-10 export settings\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from torchvision import datasets\n",
        "from PIL import Image\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "# Paths\n",
        "batches_dir = Path(\"/root/data/cifar10/cifar-10-batches-py\")  # CIFAR-10 binary batches location\n",
        "export_root = Path(\"/root/data/cifar10_extracted\")\n",
        "overwrite = False  # set True to re-export\n",
        "val_fraction = 0.5  # fraction of test set to use for validation\n",
        "\n",
        "# Ensure parent folder exists\n",
        "batches_dir.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# If CIFAR-10 not found locally, download it first\n",
        "if not batches_dir.exists():\n",
        "    print(\"[INFO] CIFAR-10 not found locally. Downloading...\")\n",
        "    datasets.CIFAR10(root=str(batches_dir.parent), train=True, download=True)\n",
        "    datasets.CIFAR10(root=str(batches_dir.parent), train=False, download=True)\n",
        "else:\n",
        "    print(\"[OK] CIFAR-10 already exists locally.\")\n",
        "\n",
        "root_for_torchvision = batches_dir.parent  # torchvision will find 'cifar-10-batches-py' under this root\n",
        "\n",
        "# Export if needed\n",
        "if export_root.exists() and not overwrite:\n",
        "    print(f\"[SKIP] {export_root} already exists. Set overwrite=True to re-export.\")\n",
        "else:\n",
        "    # Remove existing and recreate\n",
        "    if export_root.exists():\n",
        "        shutil.rmtree(export_root)\n",
        "    (export_root / \"train\").mkdir(parents=True, exist_ok=True)\n",
        "    (export_root / \"val\").mkdir(parents=True, exist_ok=True)\n",
        "    (export_root / \"test\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Load CIFAR-10 from existing or freshly downloaded batches\n",
        "    ds_train = datasets.CIFAR10(root=str(root_for_torchvision), train=True, download=False)\n",
        "    ds_test  = datasets.CIFAR10(root=str(root_for_torchvision), train=False, download=False)\n",
        "    classes = ds_train.classes\n",
        "    print(\"CIFAR-10 classes:\", classes)\n",
        "\n",
        "    # Split test dataset into val/test\n",
        "    indices = np.random.permutation(len(ds_test))\n",
        "    val_size = int(len(ds_test) * val_fraction)\n",
        "    val_indices = indices[:val_size]\n",
        "    test_indices = indices[val_size:]\n",
        "\n",
        "    # Helper to export a portion of a dataset\n",
        "    def export_dataset(dataset, indices, split_name: str):\n",
        "        for c in classes:\n",
        "            (export_root / split_name / c).mkdir(parents=True, exist_ok=True)\n",
        "        for idx in tqdm(indices, desc=f\"Exporting {split_name}\"):\n",
        "            img, label = dataset[idx]\n",
        "            cls = classes[label]\n",
        "            out_path = export_root / split_name / cls / f\"{split_name}_{cls}_{idx:05d}.png\"\n",
        "            img.save(out_path, format=\"PNG\", optimize=True)\n",
        "\n",
        "    # Export train\n",
        "    for c in classes:\n",
        "        (export_root / \"train\" / c).mkdir(parents=True, exist_ok=True)\n",
        "    for idx in tqdm(range(len(ds_train)), desc=\"Exporting train\"):\n",
        "        img, label = ds_train[idx]\n",
        "        cls = classes[label]\n",
        "        out_path = export_root / \"train\" / cls / f\"train_{cls}_{idx:05d}.png\"\n",
        "        img.save(out_path, format=\"PNG\", optimize=True)\n",
        "\n",
        "    # Export validation and test splits\n",
        "    export_dataset(ds_test, val_indices, \"val\")\n",
        "    export_dataset(ds_test, test_indices, \"test\")\n",
        "\n",
        "print(f\"[DONE] CIFAR-10 exported to: {export_root.resolve()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare DataLoaders\n",
        "\n",
        "Define the dataset root and load the training, validation, and test datasets using the custom `ClassificationDataset` class.  Set the number of workers depending on whether a GPU is available.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classes (10): ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
            "Train: 50000, Val: 5000, Test: 5000\n"
          ]
        }
      ],
      "source": [
        "# Path to your dataset root directory. This folder contains 'train', 'val', and 'test' subfolders.\n",
        "data_root = str(Path(\"/root/data/cifar10_extracted\").resolve())\n",
        "\n",
        "# Image size used for resizing. ConvNeXt models typically expect 224×224 inputs.\n",
        "img_size = 224\n",
        "\n",
        "# Number of worker processes for data loading. Adjust based on your CPU cores and GPU. A fallback of 0 for CPU-only.\n",
        "num_workers = 4 if torch.cuda.is_available() else 0\n",
        "\n",
        "# Define transforms for training and validation/test using our custom transform\n",
        "transform_train = ClassificationTransform(size=img_size, train=True)\n",
        "transform_val   = ClassificationTransform(size=img_size, train=False)\n",
        "\n",
        "# Load training dataset and determine class mapping\n",
        "ds_train = ClassificationDataset(data_root, 'train', transform_train)\n",
        "class_to_idx = ds_train.class_to_idx\n",
        "num_classes = len(class_to_idx)\n",
        "if num_classes < 2:\n",
        "    raise RuntimeError('Need at least two classes in the training data.')\n",
        "\n",
        "# Choose which split to use for validation: we explicitly have a 'val' folder\n",
        "val_split_name = 'val'\n",
        "\n",
        "# Load validation and test datasets with the same class mapping\n",
        "ds_val  = ClassificationDataset(data_root, val_split_name, transform_val, class_to_idx=class_to_idx)\n",
        "ds_test = ClassificationDataset(data_root, 'test', transform_val, class_to_idx=class_to_idx)\n",
        "\n",
        "print(f\"Classes ({num_classes}): {list(class_to_idx.keys())}\")\n",
        "print(f\"Train: {len(ds_train)}, Val: {len(ds_val)}, Test: {len(ds_test)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Logging Helpers\n",
        "\n",
        "Utilities to save per-epoch metrics into CSV files and to generate line plots and confusion matrices.  All artifacts are written under the `./artifacts` directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Directory to store artifacts (CSV logs, curves, checkpoints)\n",
        "ARTIFACT_ROOT = Path(\"./artifacts/cifar10_optuna\")\n",
        "ARTIFACT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Flag to evaluate test set each epoch (be cautious of leakage).  Set True to log test metrics per epoch.\n",
        "EVAL_TEST_EACH_EPOCH = True\n",
        "\n",
        "def _now():\n",
        "    return time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
        "\n",
        "\n",
        "def save_epoch_logcsv(\n",
        "    out_dir: Path,\n",
        "    trial_num: int,\n",
        "    split: str,\n",
        "    epoch: int,\n",
        "    metrics: Dict[str, float],\n",
        "    extra: Dict[str, str] = None\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Append an epoch line into out_dir/'epoch_logs.csv' with columns:\n",
        "    time, trial, split, epoch, loss, acc, precision, recall, f1, specificity, <extras...>\n",
        "    \"\"\"\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    fpath = out_dir / \"epoch_logs.csv\"\n",
        "\n",
        "    row = {\n",
        "        \"time\": _now(),\n",
        "        \"trial\": trial_num,\n",
        "        \"split\": split,\n",
        "        \"epoch\": epoch,\n",
        "        \"loss\": metrics.get(\"loss\", None),\n",
        "        \"acc\": metrics.get(\"acc\", None),\n",
        "        \"precision\": metrics.get(\"precision\", None),\n",
        "        \"recall\": metrics.get(\"recall\", None),\n",
        "        \"f1\": metrics.get(\"f1\", None),\n",
        "        \"specificity\": metrics.get(\"specificity\", None),\n",
        "    }\n",
        "    if extra:\n",
        "        row.update(extra)\n",
        "\n",
        "    write_header = not fpath.exists()\n",
        "    with open(fpath, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        w = csv.DictWriter(f, fieldnames=list(row.keys()))\n",
        "        if write_header:\n",
        "            w.writeheader()\n",
        "        w.writerow(row)\n",
        "\n",
        "\n",
        "def plot_lines(line_dict: Dict[str, List[float]], title: str, x_label: str, y_label: str, out_path: Path):\n",
        "    import matplotlib.pyplot as plt\n",
        "    if not line_dict:\n",
        "        return\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    max_len = max(len(v) for v in line_dict.values())\n",
        "    epochs = range(1, max_len + 1)\n",
        "    for name, y in line_dict.items():\n",
        "        plt.plot(epochs[:len(y)], y, label=name, linewidth=2)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(x_label)\n",
        "    plt.ylabel(y_label)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_path)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def plot_confusion_matrix_matplotlib(cm: np.ndarray, class_names: List[str], out_path: Path, title: str = \"Confusion Matrix\"):\n",
        "    import matplotlib.pyplot as plt\n",
        "    if cm.size == 0:\n",
        "        return\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    plt.imshow(cm, interpolation='nearest')\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(class_names))\n",
        "    plt.xticks(tick_marks, class_names, rotation=45)\n",
        "    plt.yticks(tick_marks, class_names)\n",
        "    thresh = cm.max() / 2.0 if cm.max() > 0 else 0\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            plt.text(j, i, format(int(cm[i, j])), ha=\"center\", va=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_path)\n",
        "    plt.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optuna Objective Function\n",
        "\n",
        "Define the objective function for Optuna.  For each trial, the model is trained for a small number of epochs with sampled hyperparameters.  Metrics for train, validation, and test (if enabled) are logged to CSV files, and loss/accuracy curves along with confusion matrices are generated for each trial.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def objective(trial: optuna.Trial) -> float:\n",
        "    # ===== hyperparameters =====\n",
        "    lr        = trial.suggest_float('lr', 1e-5, 5e-3, log=True)\n",
        "    wd        = trial.suggest_float('weight_decay', 1e-6, 5e-3, log=True)\n",
        "    dropout   = trial.suggest_float('dropout', 0.0, 0.4)\n",
        "    opt_name  = trial.suggest_categorical('optimizer', ['adamw', 'sgd'])\n",
        "    batch_size= trial.suggest_categorical('batch_size', [8, 16])\n",
        "    # Force epochs to a fixed small integer for tuning\n",
        "    epochs    = trial.suggest_int('epochs', 3, 3)  # small for tuning\n",
        "\n",
        "    # Print the sampled hyperparameters for this trial\n",
        "    print(f\"Starting Trial {trial.number}: lr={lr:.5f}, wd={wd:.6f}, dropout={dropout:.2f}, optimizer={opt_name}, batch_size={batch_size}, epochs={epochs}\", flush=True)\n",
        "\n",
        "    device = device_auto()\n",
        "\n",
        "    # ===== DataLoaders (uses global num_workers) =====\n",
        "    dl_train = DataLoader(ds_train, batch_size=batch_size, shuffle=True,  num_workers=num_workers, pin_memory=True)\n",
        "    dl_val   = DataLoader(ds_val,   batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "    dl_test  = DataLoader(ds_test,  batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "    # ===== Model & Optimizer =====\n",
        "    model = build_convnext_classifier(MANUAL_CONVNEXT_VARIANT, num_classes, dropout).to(device)\n",
        "    optimizer = (torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "                 if opt_name == 'adamw'\n",
        "                 else torch.optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9, nesterov=True))\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # ===== Logs for curves =====\n",
        "    tr_losses, tr_accs = [], []\n",
        "    va_losses, va_accs = [], []\n",
        "    te_losses, te_accs = [], []\n",
        "\n",
        "    # Directory for this trial\n",
        "    out_trial_dir = ARTIFACT_ROOT / f\"trial_{trial.number:03d}\"\n",
        "    out_trial_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    best_acc = -1.0\n",
        "    best_ckpt = out_trial_dir / \"best_model.pth\"\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        # ---- train ----\n",
        "        tr_loss, tr_acc = train_one_epoch_cls(model, dl_train, optimizer, criterion, device, epoch-1, epochs)\n",
        "        tr_losses.append(tr_loss); tr_accs.append(tr_acc)\n",
        "        save_epoch_logcsv(out_trial_dir, trial.number, \"train\", epoch, {\n",
        "            \"loss\": tr_loss, \"acc\": tr_acc, \"precision\": None, \"recall\": None, \"f1\": None, \"specificity\": None\n",
        "        })\n",
        "\n",
        "        # ---- val ----\n",
        "        val_metrics = eval_cls_metrics(model, dl_val, criterion, device)\n",
        "        va_losses.append(val_metrics['loss']); va_accs.append(val_metrics['acc'])\n",
        "        save_epoch_logcsv(out_trial_dir, trial.number, \"val\", epoch, val_metrics)\n",
        "\n",
        "        # Print train and validation metrics for this epoch\n",
        "        print(f\"Trial {trial.number} Epoch {epoch}/{epochs} - Train loss: {tr_loss:.4f}, acc: {tr_acc:.4f}; Val loss: {val_metrics['loss']:.4f}, acc: {val_metrics['acc']:.4f}\", flush=True)\n",
        "\n",
        "        # ---- test (optional) ----\n",
        "        if EVAL_TEST_EACH_EPOCH:\n",
        "            test_metrics = eval_cls_metrics(model, dl_test, criterion, device)\n",
        "            te_losses.append(test_metrics['loss']); te_accs.append(test_metrics['acc'])\n",
        "            save_epoch_logcsv(out_trial_dir, trial.number, \"test\", epoch, test_metrics)\n",
        "            # Print test metrics for this epoch\n",
        "            print(f\"Trial {trial.number} Epoch {epoch}/{epochs} - Test loss: {test_metrics['loss']:.4f}, acc: {test_metrics['acc']:.4f}\", flush=True)\n",
        "\n",
        "        # Report to Optuna (minimize 1 - val_acc)\n",
        "        trial.report(1.0 - val_metrics['acc'], step=epoch)\n",
        "        if trial.should_prune():\n",
        "            raise optuna.TrialPruned()\n",
        "\n",
        "        # Save best by val acc\n",
        "        if val_metrics['acc'] > best_acc:\n",
        "            best_acc = val_metrics['acc']\n",
        "            torch.save({\n",
        "                \"model\": model.state_dict(),\n",
        "                \"variant\": MANUAL_CONVNEXT_VARIANT,\n",
        "                \"num_classes\": num_classes,\n",
        "                \"classes\": list(class_to_idx.keys())\n",
        "            }, best_ckpt)\n",
        "\n",
        "    # curves\n",
        "    plot_lines({\"Train Loss\": tr_losses, \"Val Loss\": va_losses},\n",
        "               \"Train vs Val Loss\", \"Epoch\", \"Loss\", out_trial_dir / \"loss_curve.png\")\n",
        "    plot_lines({\"Train Acc\": tr_accs, \"Val Acc\": va_accs},\n",
        "               \"Train vs Val Accuracy\", \"Epoch\", \"Accuracy\", out_trial_dir / \"acc_curve.png\")\n",
        "    if EVAL_TEST_EACH_EPOCH and te_losses:\n",
        "        plot_lines({\"Test Loss\": te_losses}, \"Test Loss\", \"Epoch\", \"Loss\", out_trial_dir / \"test_loss_curve.png\")\n",
        "    if EVAL_TEST_EACH_EPOCH and te_accs:\n",
        "        plot_lines({\"Test Acc\": te_accs}, \"Test Accuracy\", \"Epoch\", \"Accuracy\", out_trial_dir / \"test_acc_curve.png\")\n",
        "\n",
        "    # final confusion matrix on VAL and TEST of final epoch\n",
        "    with torch.no_grad():\n",
        "        # VAL\n",
        "        all_preds_cm, all_labels_cm = [], []\n",
        "        for x_val, y_val in dl_val:\n",
        "            x_val = x_val.to(device, non_blocking=True)\n",
        "            y_val = y_val.to(device, non_blocking=True)\n",
        "            logits_val = model(x_val)\n",
        "            all_preds_cm.append(logits_val.argmax(1).detach().cpu().numpy())\n",
        "            all_labels_cm.append(y_val.detach().cpu().numpy())\n",
        "        if all_labels_cm:\n",
        "            y_true_cm = np.concatenate(all_labels_cm)\n",
        "            y_pred_cm = np.concatenate(all_preds_cm)\n",
        "            cm_val = confusion_matrix(y_true_cm, y_pred_cm)\n",
        "            plot_confusion_matrix_matplotlib(cm_val, list(class_to_idx.keys()), out_trial_dir / \"val_confusion_matrix.png\", \"Validation Confusion Matrix\")\n",
        "        # TEST\n",
        "        if EVAL_TEST_EACH_EPOCH:\n",
        "            all_preds_cm, all_labels_cm = [], []\n",
        "            for x_te, y_te in dl_test:\n",
        "                x_te = x_te.to(device, non_blocking=True)\n",
        "                y_te = y_te.to(device, non_blocking=True)\n",
        "                logits_te = model(x_te)\n",
        "                all_preds_cm.append(logits_te.argmax(1).detach().cpu().numpy())\n",
        "                all_labels_cm.append(y_te.detach().cpu().numpy())\n",
        "            if all_labels_cm:\n",
        "                y_true_cm = np.concatenate(all_labels_cm)\n",
        "                y_pred_cm = np.concatenate(all_preds_cm)\n",
        "                cm_test = confusion_matrix(y_true_cm, y_pred_cm)\n",
        "                plot_confusion_matrix_matplotlib(cm_test, list(class_to_idx.keys()), out_trial_dir / \"test_confusion_matrix.png\", \"Test Confusion Matrix\")\n",
        "\n",
        "    # Print final result of trial\n",
        "    print(f\"Finished Trial {trial.number}. Best validation accuracy: {best_acc:.4f}\", flush=True)\n",
        "\n",
        "    # objective: minimize 1 - best val acc\n",
        "    return 1.0 - float(best_acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyperparameter Optimization with Optuna\n",
        "\n",
        "Create an Optuna study, run a few trials, and report the best hyperparameters found.  The number of trials is set small by default to keep runtime reasonable.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-10-25 02:24:33,433] A new study created in memory with name: no-name-0cc273d4-4ae7-4b77-b666-689035e63f97\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Trial 0: lr=0.00010, wd=0.003286, dropout=0.29, optimizer=adamw, batch_size=8, epochs=3\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3bb2e2c175db4f42af799043d5362fe0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/114M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 0 Epoch 1/3 - Train loss: 0.6321, acc: 0.7788; Val loss: 0.2591, acc: 0.9102\n",
            "Trial 0 Epoch 1/3 - Test loss: 0.2839, acc: 0.8996\n",
            "Trial 0 Epoch 2/3 - Train loss: 0.2731, acc: 0.9069; Val loss: 0.2488, acc: 0.9158\n",
            "Trial 0 Epoch 2/3 - Test loss: 0.2458, acc: 0.9164\n",
            "Trial 0 Epoch 3/3 - Train loss: 0.2122, acc: 0.9278; Val loss: 0.1794, acc: 0.9396\n",
            "Trial 0 Epoch 3/3 - Test loss: 0.1853, acc: 0.9392\n",
            "Finished Trial 0. Best validation accuracy: 0.9396\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-10-25 02:42:14,768] Trial 0 finished with value: 0.06040000000000001 and parameters: {'lr': 0.0001025350969016849, 'weight_decay': 0.0032859708169642424, 'dropout': 0.292797576724562, 'optimizer': 'adamw', 'batch_size': 8, 'epochs': 3}. Best is trial 0 with value: 0.06040000000000001.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Optuna] Trial 0 finished with value: 0.0604, params: {'lr': 0.0001025350969016849, 'weight_decay': 0.0032859708169642424, 'dropout': 0.292797576724562, 'optimizer': 'adamw', 'batch_size': 8, 'epochs': 3}\n",
            "[Optuna]     Best value so far: 0.0604\n",
            "Number of finished trials: 1\n",
            "Best trial:\n",
            "Validation accuracy: 0.9396\n",
            "Hyperparameters:\n",
            "    lr: 0.0001025350969016849\n",
            "    weight_decay: 0.0032859708169642424\n",
            "    dropout: 0.292797576724562\n",
            "    optimizer: adamw\n",
            "    batch_size: 8\n",
            "    epochs: 3\n"
          ]
        }
      ],
      "source": [
        "# Reset Optuna logging level to show information\n",
        "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
        "\n",
        "# Callback to print results at the end of each trial\n",
        "\n",
        "def print_callback(study, trial):\n",
        "    print(f\"[Optuna] Trial {trial.number} finished with value: {trial.value:.4f}, params: {trial.params}\", flush=True)\n",
        "    print(f\"[Optuna]     Best value so far: {study.best_value:.4f}\", flush=True)\n",
        "\n",
        "seed_everything(42)\n",
        "study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
        "study.optimize(objective, n_trials=1, timeout=None, callbacks=[print_callback])\n",
        "\n",
        "print('Number of finished trials:', len(study.trials))\n",
        "best_trial = study.best_trial\n",
        "\n",
        "print('Best trial:')\n",
        "print(f\"Validation accuracy: {1.0 - best_trial.value:.4f}\")\n",
        "print('Hyperparameters:')\n",
        "for key, value in best_trial.params.items():\n",
        "    print(f\"    {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final Training with Best Hyperparameters\n",
        "\n",
        "Train a fresh model using the best hyperparameters discovered by Optuna.  Record metrics for train, validation, and test sets at each epoch, produce curves, and generate confusion matrices for the final epoch.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3 - Train loss: 0.4552, acc: 0.8492; Val loss: 0.2387, acc: 0.9202; Test loss: 0.2589, acc: 0.9176\n",
            "Epoch 2/3 - Train loss: 0.2710, acc: 0.9093; Val loss: 0.2354, acc: 0.9170; Test loss: 0.2327, acc: 0.9238\n",
            "Epoch 3/3 - Train loss: 0.2115, acc: 0.9289; Val loss: 0.1774, acc: 0.9424; Test loss: 0.1947, acc: 0.9382\n",
            "[DONE] Final training complete. Logs and plots are stored in artifacts/cifar10_optuna/final_best_run\n"
          ]
        }
      ],
      "source": [
        "# Retrieve the best hyperparameters\n",
        "best_params = study.best_trial.params\n",
        "# Number of epochs for the final training run\n",
        "final_epochs    = int(best_params.get('epochs', 5))\n",
        "final_batchsize = int(best_params.get('batch_size', 16))\n",
        "final_lr        = float(best_params['lr'])\n",
        "final_wd        = float(best_params['weight_decay'])\n",
        "final_dropout   = float(best_params['dropout'])\n",
        "final_opt_name  = best_params['optimizer']\n",
        "\n",
        "# Set up directory for final run\n",
        "final_dir = ARTIFACT_ROOT / \"final_best_run\"\n",
        "final_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# DataLoaders\n",
        "device = device_auto()\n",
        "final_dl_train = DataLoader(ds_train, batch_size=final_batchsize, shuffle=True,  num_workers=num_workers, pin_memory=True)\n",
        "final_dl_val   = DataLoader(ds_val,   batch_size=final_batchsize, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "final_dl_test  = DataLoader(ds_test,  batch_size=final_batchsize, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "# Model & optimizer\n",
        "final_model = build_convnext_classifier(MANUAL_CONVNEXT_VARIANT, num_classes, final_dropout).to(device)\n",
        "final_optimizer = (torch.optim.AdamW(final_model.parameters(), lr=final_lr, weight_decay=final_wd)\n",
        "                   if final_opt_name == 'adamw'\n",
        "                   else torch.optim.SGD(final_model.parameters(), lr=final_lr, weight_decay=final_wd, momentum=0.9, nesterov=True))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Containers to store metrics\n",
        "train_losses, train_accs = [], []\n",
        "val_losses, val_accs     = [], []\n",
        "test_losses, test_accs   = [], []\n",
        "\n",
        "best_val_acc = -1.0\n",
        "best_ckpt = final_dir / \"best_model.pth\"\n",
        "\n",
        "for epoch in range(1, final_epochs+1):\n",
        "    # Train\n",
        "    tr_loss, tr_acc = train_one_epoch_cls(final_model, final_dl_train, final_optimizer, criterion, device, epoch-1, final_epochs)\n",
        "    train_losses.append(tr_loss); train_accs.append(tr_acc)\n",
        "    save_epoch_logcsv(final_dir, -1, \"train\", epoch, {\n",
        "        \"loss\": tr_loss, \"acc\": tr_acc, \"precision\": None, \"recall\": None, \"f1\": None, \"specificity\": None\n",
        "    })\n",
        "\n",
        "    # Validate\n",
        "    val_metrics = eval_cls_metrics(final_model, final_dl_val, criterion, device)\n",
        "    val_losses.append(val_metrics['loss']); val_accs.append(val_metrics['acc'])\n",
        "    save_epoch_logcsv(final_dir, -1, \"val\", epoch, val_metrics)\n",
        "\n",
        "    # Test\n",
        "    test_metrics = None\n",
        "    if EVAL_TEST_EACH_EPOCH:\n",
        "        test_metrics = eval_cls_metrics(final_model, final_dl_test, criterion, device)\n",
        "        test_losses.append(test_metrics['loss']); test_accs.append(test_metrics['acc'])\n",
        "        save_epoch_logcsv(final_dir, -1, \"test\", epoch, test_metrics)\n",
        "\n",
        "    # Print metrics for this epoch\n",
        "    msg = f\"Epoch {epoch}/{final_epochs} - Train loss: {tr_loss:.4f}, acc: {tr_acc:.4f}; Val loss: {val_metrics['loss']:.4f}, acc: {val_metrics['acc']:.4f}\"\n",
        "    if test_metrics is not None:\n",
        "        msg += f\"; Test loss: {test_metrics['loss']:.4f}, acc: {test_metrics['acc']:.4f}\"\n",
        "    print(msg, flush=True)\n",
        "\n",
        "    # Save best based on validation accuracy\n",
        "    if val_metrics['acc'] > best_val_acc:\n",
        "        best_val_acc = val_metrics['acc']\n",
        "        torch.save({\n",
        "            \"model\": final_model.state_dict(),\n",
        "            \"variant\": MANUAL_CONVNEXT_VARIANT,\n",
        "            \"num_classes\": num_classes,\n",
        "            \"classes\": list(class_to_idx.keys())\n",
        "        }, best_ckpt)\n",
        "\n",
        "# Generate curves for the final run\n",
        "plot_lines({\"Train Loss\": train_losses, \"Val Loss\": val_losses}, \"Final: Train vs Val Loss\", \"Epoch\", \"Loss\", final_dir/\"loss_curve.png\")\n",
        "plot_lines({\"Train Acc\": train_accs, \"Val Acc\": val_accs}, \"Final: Train vs Val Accuracy\", \"Epoch\", \"Accuracy\", final_dir/\"acc_curve.png\")\n",
        "if EVAL_TEST_EACH_EPOCH and test_losses:\n",
        "    plot_lines({\"Test Loss\": test_losses}, \"Final: Test Loss\", \"Epoch\", \"Loss\", final_dir/\"test_loss_curve.png\")\n",
        "if EVAL_TEST_EACH_EPOCH and test_accs:\n",
        "    plot_lines({\"Test Acc\": test_accs}, \"Final: Test Accuracy\", \"Epoch\", \"Accuracy\", final_dir/\"test_acc_curve.png\")\n",
        "\n",
        "# Confusion matrices for final epoch (val and test)\n",
        "with torch.no_grad():\n",
        "    # Validation\n",
        "    preds, labels = [], []\n",
        "    for x_val, y_val in final_dl_val:\n",
        "        x_val = x_val.to(device, non_blocking=True)\n",
        "        y_val = y_val.to(device, non_blocking=True)\n",
        "        logits_val = final_model(x_val)\n",
        "        preds.append(logits_val.argmax(1).detach().cpu().numpy())\n",
        "        labels.append(y_val.detach().cpu().numpy())\n",
        "    if labels:\n",
        "        y_true = np.concatenate(labels)\n",
        "        y_pred = np.concatenate(preds)\n",
        "        cm_val = confusion_matrix(y_true, y_pred)\n",
        "        plot_confusion_matrix_matplotlib(cm_val, list(class_to_idx.keys()), final_dir/\"val_confusion_matrix.png\", \"Final Validation Confusion Matrix\")\n",
        "\n",
        "    # Test\n",
        "    if EVAL_TEST_EACH_EPOCH:\n",
        "        preds, labels = [], []\n",
        "        for x_te, y_te in final_dl_test:\n",
        "            x_te = x_te.to(device, non_blocking=True)\n",
        "            y_te = y_te.to(device, non_blocking=True)\n",
        "            logits_te = final_model(x_te)\n",
        "            preds.append(logits_te.argmax(1).detach().cpu().numpy())\n",
        "            labels.append(y_te.detach().cpu().numpy())\n",
        "        if labels:\n",
        "            y_true = np.concatenate(labels)\n",
        "            y_pred = np.concatenate(preds)\n",
        "            cm_test = confusion_matrix(y_true, y_pred)\n",
        "            plot_confusion_matrix_matplotlib(cm_test, list(class_to_idx.keys()), final_dir/\"test_confusion_matrix.png\", \"Final Test Confusion Matrix\")\n",
        "\n",
        "print(f\"[DONE] Final training complete. Logs and plots are stored in {final_dir}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
